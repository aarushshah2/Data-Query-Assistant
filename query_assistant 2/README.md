# ğŸ¤– Intelligent Data Query Assistant (Local â€” Ollama)

A production-ready AI-powered system that lets non-technical users query PostgreSQL databases using plain English â€” **100% local, no API keys, no cloud**.

---

## ğŸ“ Project Structure

```
query_assistant/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py           # Environment & settings
â”‚   â”œâ”€â”€ database.py         # PostgreSQL connection pool
â”‚   â”œâ”€â”€ schema_inspector.py # Introspects DB schema for AI context
â”‚   â”œâ”€â”€ nl_to_sql.py        # Ollama: NL â†’ SQL (local LLM)
â”‚   â”œâ”€â”€ sql_validator.py    # Safety validation layer
â”‚   â”œâ”€â”€ query_executor.py   # Safe query execution
â”‚   â””â”€â”€ logger.py           # Query audit logger
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ query_handler.py    # Orchestrates the full pipeline
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ app.py              # Streamlit chatbot UI
â”œâ”€â”€ migrations/
â”‚   â””â”€â”€ init.sql            # DB schema + sample data
â”œâ”€â”€ .env.example
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup

### 1. Install Ollama
```bash
# macOS / Linux
curl -fsSL https://ollama.com/install.sh | sh

# Windows: download from https://ollama.com/download
```

### 2. Pull a model (choose one)
```bash
ollama pull llama3.1          # Recommended â€” best SQL quality (~4.7 GB)
ollama pull codellama         # Code-focused alternative (~3.8 GB)
ollama pull mistral           # Lighter option (~4.1 GB)
ollama pull qwen2.5-coder     # Excellent for SQL (~4.7 GB)
```

### 3. Start Ollama
```bash
ollama serve
# Runs on http://localhost:11434 by default
```

### 4. Install Python dependencies
```bash
pip install -r requirements.txt
```

### 5. Configure environment
```bash
cp .env.example .env
# Edit .env â€” set your DB credentials and model name
```

### 6. Initialize database
```bash
psql -U your_user -d your_db -f migrations/init.sql
```

### 7. Run the app
```bash
streamlit run ui/app.py
```

---

## ğŸ¦™ Recommended Models (best â†’ lightest)

| Model | Pull command | Size | SQL Quality |
|---|---|---|---|
| `llama3.1` | `ollama pull llama3.1` | 4.7 GB | â­â­â­â­â­ |
| `qwen2.5-coder` | `ollama pull qwen2.5-coder` | 4.7 GB | â­â­â­â­â­ |
| `codellama` | `ollama pull codellama` | 3.8 GB | â­â­â­â­ |
| `mistral` | `ollama pull mistral` | 4.1 GB | â­â­â­â­ |
| `phi3` | `ollama pull phi3` | 2.3 GB | â­â­â­ |

Set your choice in `.env`:
```
OLLAMA_MODEL=llama3.1
```

The **sidebar in the UI** also lets you switch models on the fly from whatever you have pulled.

---

## ğŸ” Security Features

| Feature | Description |
|---|---|
| SELECT-only enforcement | Blocks INSERT, UPDATE, DELETE, DROP, ALTER |
| Multi-statement prevention | Blocks semicolon-separated chained queries |
| Restricted table blocklist | Prevents access to `query_logs`, `users`, `secrets` |
| Automatic LIMIT injection | Caps results at 500 rows if no LIMIT specified |
| Read-only DB transaction | Even if validation fails, PostgreSQL rejects writes |
| Schema-aware AI | AI only sees real tables/columns â€” no hallucinations |
| 100% local | No data leaves your machine |

---

## ğŸ§ª Example Questions

- "Show me leads from Texas created in the last 7 days"
- "How many customers signed up this month?"
- "List vehicles that are not running"
- "Show top 10 states by number of leads"
- "What is the average deal value by sales rep?"

---

## ğŸ—ï¸ Architecture

```
User Question
     â†“
[Schema Inspector] â†’ loads real table/column context
     â†“
[NL â†’ SQL (Ollama local LLM)] â†’ generates PostgreSQL SELECT
     â†“
[SQL Validator] â†’ safety checks, LIMIT injection
     â†“
[Query Executor] â†’ runs in READ ONLY transaction, times execution
     â†“
[Audit Logger] â†’ stores question, SQL, timing to DB
     â†“
[Streamlit UI] â†’ displays results in chatbot format
```

